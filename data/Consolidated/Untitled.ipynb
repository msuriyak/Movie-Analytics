{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg = pd.read_csv('films_globe.csv', index_col=0)\n",
    "res = []\n",
    "for year in gg.index.unique():\n",
    "    temp = gg.loc[year]\n",
    "    if type(temp) == pd.core.series.Series:\n",
    "        res += [1]\n",
    "    else: \n",
    "        res += [1] + [0 for i in range(len(temp) -1 )]\n",
    "res = np.array(res)\n",
    "gg['Globe winner'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Film</th>\n",
       "      <th>Director</th>\n",
       "      <th>Producers</th>\n",
       "      <th>Globe winner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>A Place in the Sun</td>\n",
       "      <td>George Stevens</td>\n",
       "      <td>George Stevens</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>Bright Victory</td>\n",
       "      <td>Mark Robson</td>\n",
       "      <td>Robert Buckner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>Detective Story</td>\n",
       "      <td>William Wyler</td>\n",
       "      <td>William Wyler</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>Quo Vadis</td>\n",
       "      <td>Mervyn LeRoy</td>\n",
       "      <td>Sam Zimbalist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>A Streetcar Named Desire</td>\n",
       "      <td>Elia Kazan</td>\n",
       "      <td>Charles K. Feldman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>The Greatest Show on Earth</td>\n",
       "      <td>Cecil B. DeMille</td>\n",
       "      <td>Cecil B. DeMille</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>Come Back, Little Sheba</td>\n",
       "      <td>Daniel Mann</td>\n",
       "      <td>Hal B. Wallis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>The Happy Time</td>\n",
       "      <td>Richard Fleischer</td>\n",
       "      <td>Earl Fenton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>High Noon</td>\n",
       "      <td>Fred Zinnemann</td>\n",
       "      <td>Stanley Kramer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>The Thief</td>\n",
       "      <td>Russell Rouse</td>\n",
       "      <td>Clarence Greene</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Film           Director           Producers  \\\n",
       "Year                                                                       \n",
       "1951          A Place in the Sun      George Stevens      George Stevens   \n",
       "1951               Bright Victory        Mark Robson      Robert Buckner   \n",
       "1951              Detective Story      William Wyler       William Wyler   \n",
       "1951                   Quo Vadis        Mervyn LeRoy       Sam Zimbalist   \n",
       "1951    A Streetcar Named Desire          Elia Kazan  Charles K. Feldman   \n",
       "1952  The Greatest Show on Earth    Cecil B. DeMille    Cecil B. DeMille   \n",
       "1952      Come Back, Little Sheba        Daniel Mann       Hal B. Wallis   \n",
       "1952               The Happy Time  Richard Fleischer         Earl Fenton   \n",
       "1952                   High Noon      Fred Zinnemann      Stanley Kramer   \n",
       "1952                    The Thief      Russell Rouse     Clarence Greene   \n",
       "\n",
       "      Globe winner  \n",
       "Year                \n",
       "1951             1  \n",
       "1951             0  \n",
       "1951             0  \n",
       "1951             0  \n",
       "1951             0  \n",
       "1952             1  \n",
       "1952             0  \n",
       "1952             0  \n",
       "1952             0  \n",
       "1952             0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf = pd.read_csv(\"films_bafta.csv\", index_col=0)\n",
    "res = []\n",
    "for year in bf.index.unique():\n",
    "    temp = bf.loc[year]\n",
    "    if type(temp) == pd.core.series.Series:\n",
    "        res += [1]\n",
    "    else: \n",
    "        res += [1] + [0 for i in range(len(temp) -1 )]\n",
    "res = np.array(res)\n",
    "bf['BAFTA winner'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>BAFTA winner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>The Apartment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>The 400 Blows</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>The Angry Silence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>The Adventure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>La Dolce Vita</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  BAFTA winner\n",
       "year                                 \n",
       "1960      The Apartment             1\n",
       "1960      The 400 Blows             0\n",
       "1960  The Angry Silence             0\n",
       "1960      The Adventure             0\n",
       "1960      La Dolce Vita             0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Critics%27_Choice_Movie_Award_for_Best_Picture'\n",
    "html = urllib.request.urlopen(url)\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-32a30d03268a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ul'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'1995'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'li'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'2010'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'li'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'2010'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'li'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "res = soup.findAll('ul')\n",
    "for item in res:\n",
    "    if '1995' in item.find('li').contents or '2010' in item.find('li').contents or '2010' in item.find('li').contents:\n",
    "        data = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Main!!!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create CSVs from all tables on a Wikipedia article.\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import platform\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def scrape(url=\"https://en.wikipedia.org/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Female_Actor_in_a_Leading_Role\", output_name='actress'):\n",
    "    \"\"\"Create CSVs from all tables in a Wikipedia article.\n",
    "\n",
    "    ARGS:\n",
    "        url (str): The full URL of the Wikipedia article to scrape tables from.\n",
    "        output_name (str): The base file name (without filepath) to write to.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read tables from Wikipedia article into list of HTML strings\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content, 'lxml')\n",
    "    # table_classes = {\"class\": [\"sortable\", \"plainrowheaders\"]}\n",
    "    table_classes = {'class': 'wikitable'}\n",
    "    wikitables = soup.findAll(\"table\", table_classes)[0:3]\n",
    "    print (len(wikitables))\n",
    "\n",
    "    # Create folder for output if it doesn't exist\n",
    "    try:\n",
    "        os.mkdir(output_name)\n",
    "    except Exception:  # Generic OS Error\n",
    "        pass\n",
    "\n",
    "    for index, table in enumerate(wikitables):\n",
    "        # Make a unique file name for each CSV\n",
    "        if index == 0:\n",
    "            filename = output_name\n",
    "        else:\n",
    "            filename = output_name + '_' + str(index)\n",
    "\n",
    "        filepath = os.path.join(output_name, filename) + '.csv'\n",
    "\n",
    "        with open(filepath, mode='w', newline='', encoding='utf-8') as output:\n",
    "            # Deal with Windows inserting an extra '\\r' in line terminators\n",
    "            if platform.system() == 'Windows':\n",
    "                kwargs = {'lineterminator': '\\n'}\n",
    "\n",
    "            csv_writer = csv.writer(output, quoting=csv.QUOTE_ALL)\n",
    "            write_html_table_to_csv(table, csv_writer)\n",
    "\n",
    "\n",
    "def write_html_table_to_csv(table, writer):\n",
    "    \"\"\"Write HTML table from Wikipedia to a CSV file.\n",
    "\n",
    "    ARGS:\n",
    "        table (bs4.Tag): The bs4 Tag object being analyzed.\n",
    "        writer (csv.writer): The csv Writer object creating the output.\n",
    "    \"\"\"\n",
    "\n",
    "    # Hold elements that span multiple rows in a list of\n",
    "    # dictionaries that track 'rows_left' and 'value'\n",
    "    saved_rowspans = []\n",
    "    for row in table.findAll(\"tr\"):\n",
    "        cells = row.findAll([\"th\", \"td\"])\n",
    "\n",
    "        # If the first row, use it to define width of table\n",
    "        if len(saved_rowspans) == 0:\n",
    "            saved_rowspans = [None for _ in cells]\n",
    "        # Insert values from cells that span into this row\n",
    "        elif len(cells) != len(saved_rowspans):\n",
    "            for index, rowspan_data in enumerate(saved_rowspans):\n",
    "                if rowspan_data is not None:\n",
    "                    # Insert the data from previous row; decrement rows left\n",
    "                    value = rowspan_data['value']\n",
    "                    cells.insert(index, value)\n",
    "\n",
    "                    if saved_rowspans[index]['rows_left'] == 1:\n",
    "                        saved_rowspans[index] = None\n",
    "                    else:\n",
    "                        saved_rowspans[index]['rows_left'] -= 1\n",
    "\n",
    "        # If an element with rowspan, save it for future cells\n",
    "        for index, cell in enumerate(cells):\n",
    "            if cell.has_attr(\"rowspan\"):\n",
    "                rowspan_data = {\n",
    "                    'rows_left': int(cell[\"rowspan\"]),\n",
    "                    'value': cell,\n",
    "                }\n",
    "                saved_rowspans[index] = rowspan_data\n",
    "\n",
    "        if cells:\n",
    "            # Clean the data of references and unusual whitespace\n",
    "            cleaned = clean_data(cells)\n",
    "\n",
    "            # Fill the row with empty columns if some are missing\n",
    "            # (Some HTML tables leave final empty cells without a <td> tag)\n",
    "            columns_missing = len(saved_rowspans) - len(cleaned)\n",
    "            if columns_missing:\n",
    "                cleaned += [None] * columns_missing\n",
    "\n",
    "            writer.writerow(cleaned)\n",
    "\n",
    "\n",
    "def clean_data(row):\n",
    "    \"\"\"Clean table row list from Wikipedia into a string for CSV.\n",
    "\n",
    "    ARGS:\n",
    "        row (bs4.ResultSet): The bs4 result set being cleaned for output.\n",
    "\n",
    "    RETURNS:\n",
    "        cleaned_cells (list[str]): List of cleaned text items in this row.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_cells = []\n",
    "\n",
    "    for cell in row:\n",
    "        # Strip references from the cell\n",
    "        references = cell.findAll(\"sup\", {\"class\": \"reference\"})\n",
    "        if references:\n",
    "            for ref in references:\n",
    "                ref.extract()\n",
    "\n",
    "        # Strip sortkeys from the cell\n",
    "        sortkeys = cell.findAll(\"span\", {\"class\": \"sortkey\"})\n",
    "        if sortkeys:\n",
    "            for ref in sortkeys:\n",
    "                ref.extract()\n",
    "\n",
    "        # Strip footnotes from text and join into a single string\n",
    "        text_items = cell.findAll(text=True)\n",
    "        no_footnotes = [text for text in text_items if text[0] != '[']\n",
    "\n",
    "        cleaned = (\n",
    "            ''.join(no_footnotes)  # Combine elements into single string\n",
    "            .replace('\\xa0', ' ')  # Replace non-breaking spaces\n",
    "            .replace('\\n', ' ')  # Replace newlines\n",
    "            .strip()\n",
    "        )\n",
    "\n",
    "        cleaned_cells += [cleaned]\n",
    "\n",
    "    return cleaned_cells\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Running Main!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-334c3ec86336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://en.wikipedia.org/wiki/Independent_Spirit_Award_for_Best_Film'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'film'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-139-21508a511af2>\u001b[0m in \u001b[0;36mscrape\u001b[0;34m(url, output_name)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mcsv_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_ALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mwrite_html_table_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-21508a511af2>\u001b[0m in \u001b[0;36mwrite_html_table_to_csv\u001b[0;34m(table, writer)\u001b[0m\n\u001b[1;32m     85\u001b[0m                     \u001b[0;34m'value'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 }\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0msaved_rowspans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrowspan_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Independent_Spirit_Award_for_Best_Film'\n",
    "scrape(url, output_name='film')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
